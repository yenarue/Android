# Deview 2018 day2



# 네이버 검색과 개인화

##### 최재걸 / 네이버 / 통합검색

[발표자료](https://www.slideshare.net/deview/224naver-search-npersonalizationfinal)

## 검색의 목적

* 검색의 의도에 맞는 검색 결과를 제공한다
* 초기 : 최대 다수의 최대 만족 추구 => 모두 같은 검색결과를 보여줬었다
* 변화 : 개인화를 시켜서 개인별 만족도를 높혀야 겠다!

## 개인화

### 필요한 케이스

모든 경우에 필요한 것이 아니다. 개인화도 일정 데이터가 모여야 필요성이 대두되는 것. 처음부터는 노노.

Precision이 나쁘면 개인화도 나쁨

![](https://image.slidesharecdn.com/224naversearchnpersonalizationfinal-181012022631/95/224-17-638.jpg?cb=1539312839)

### 3-Level Query Ambiquity

![](https://image.slidesharecdn.com/224naversearchnpersonalizationfinal-181012022631/95/224-19-638.jpg?cb=1539312839)

## 개인의 검색 의도 파악

검색의도는 사용자의 마음속에 있다. 중의적인 엔티티가 많아 파악하기 어려운 경우가 많다. 

![](https://image.slidesharecdn.com/224naversearchnpersonalizationfinal-181012022631/95/224-25-638.jpg?cb=1539312839)

인지과학에서 사람의 기억 흐름/구조를 위와 같이 정의했음

네이버에서도 위의 사람의 기억방식을 모방하여 3개 논리적인 계층 형태로 구축해봄

### HuMM (Human Memory Mirror)

Immediate Memory -> Working Memory -> Long Term Memory

* Immediate Memory : 네이버를 이용하는 각각의 활동
* Working Memory : 의미를 가지고 연속되는 일련의 활동
* Long Term Memory : 사용자의 행동 패턴

#### 예제

![](https://image.slidesharecdn.com/224naversearchnpersonalizationfinal-181012022631/95/224-30-638.jpg?cb=1539312839)

평소에 주식 검색을 자주했던 사람일지라도 현재 대중들의 핫이슈에 따라 (Immediate Memory 참조) 최종 검색 결과가 달라질 수 있도록 처리했다.

### 효과

* 클릭 비율이 증가함
* 스크롤 감소함

어느정도 워킹했따고 볼 수 있었다

### 어려운 점

데이터가 너무 Sparse 하다

* 네이버 검색 사용자의 평균 검색 횟수...
* 세션 내 평균 검색 횟수...



## 개인화 검색 확장 (ing)

### Precision 을 담보하는 방향으로 확장

* User Group : 유저를 기준으로 확장시킨다
  * Long Term Memory 의 결합을 이용

  * 특정 질의에 대한 선호가 업성도 다른 Long Term Memory 를 참조하여 결정함 

    > 여기서 '다른' 이라는 것은 다른 사람을 이야기 하는 것일까

* Query Group : Query의 Topic을 이용



## 요약

* 개인화가 필요한 경우를 3-level ambiguity를 이용해서 정의한다
* HuMM을 통해 개인의 검색 의도를 파악한다
* 특화된 개인화 서비스를 만드려고 노력한다

![](https://image.slidesharecdn.com/224naversearchnpersonalizationfinal-181012022631/95/224-42-638.jpg?cb=1539312839)

# Druid로 쉽고 빠르게 빅데이터 분석하기

##### 송은혜 / 네이버 / 컨텐츠소비통계

[발표자료](https://www.slideshare.net/deview/215-druid-data-analysis)

## Druid

* 컬럼기반 분산저장소
* Time 기반 파티셔닝
* 실시간/배치 데이터 저장기능 제공
* 데이터 질의기능 제공

## Druid vs Elasticsearch vs Kudu

Druid가 데이터 사이즈, 운영비용이 적다

아래 그림 : 드루이드 / 엘라스틱서치 / 쿠두

![](https://image.slidesharecdn.com/215druiddataanalysis-181012022617/95/215-druid-9-638.jpg?cb=1539314223)

// 폰으로 찍은 분석표

![](https://image.slidesharecdn.com/215druiddataanalysis-181012022617/95/215-druid-12-638.jpg?cb=1539314223)

## 도구

* Imply-UI
* Grafana
* Superset
* Metabase

![](https://image.slidesharecdn.com/215druiddataanalysis-181012022617/95/215-druid-24-638.jpg?cb=1539314223)



## 고급

서비스 아키텍처

![](https://image.slidesharecdn.com/215druiddataanalysis-181012022617/95/215-druid-26-638.jpg?cb=1539314223)

### 질의 기능 향상 시키기

* Spark-Druid Connector

### 저장성능 향상시키기

* Hash Partition 확장
* [Druid Spark Batch](https://github.com/metamx/druid-spark-batch)

### 편한 운영

* CDH 연동 : [cm-druid](https://github.com/knoguchi/cm-druid)
* 



# Search Reliability Engineering (부제: 지진에도 흔들리지 않는 네이버 검색시스템)

##### 김재현,손주식 / System & Solution / NAVER

[발표자료](https://www.slideshare.net/deview/216sresearchreliabilityengineering)

## 네이버 검색 시스템의 목표

* 짧은 대기 시간 : 적어도 1초안에 검색결과가 나와야 한다
* 대용량 처리 : 동시 검색량이 늘어나도 서비스에 문제가 없어야 한다

즉, 장애가 없어야 한다

## SRE 의 난제

1. 얼마나 비용 효율적인지 증명할 수 있는가?
   - 정확한 비용 측정 / 예측의 중요성
2. 장애가 발생하지 않았을 때, 예방 덕분이라는 것을 증명할 수 있는가?
   - 정확하고 구체적인 경보체계 확립이 필요
   - 정확한 사후분석 필요 (post-mortem)

시스템이 거대해질 수록 문제의 원인을 핀포인트로 추적하는 것 / 문제의 영향 범위를 확정하는 것 / 장애 복구 완료후에도 모든 구성요소의 정상화를 확인하는 것이 어려워진다.

## SRE(Site Reliability Engineering)

글로벌 스케일의 서비스를 제공하면서 시스템의 신뢰성을 보장할 수 있는 방법을 고민하는 기술 분야이자 방법론, 문화

### 복잡해..

마이크로 서비스 상에서 단일 호스트/서버 대상 지표를 수집하니 겁나 복잡해짐

-> 특정 서비스의 전체 레이어 및 서비스 군, 전체 시스템을 볼 수 있는 방법이 없다

-> **효율 정보 체계 도입**

## 효율적인 정보 체계 도입

* 기존 : 인스턴스 별로 ID가 없었음
* 변화 : 서비스 ID 발급 -> 구조 가시화 -> 성능/비용 측정

정보가 모이기 시작했다 -> 다양한 활용 지표를 고안하기 시작

## 가용량 지표 개발

기존 가용량 지표 계산법으로 계산해보면 99.998%라는 매우 높은 숫자가 나옴

하지만 1년동안 10분 장애 -> 검색 포털에서 이 것은 엄청난 재앙

* 대용량 분산 시스템 특성 : 특정 서버에 문제가 생기면 다른 서버들이 영향을 받음 (에러전파)

그래서 아예 새로운 지표를 개발함. (네이버 검색 포털을 위한...)

* 부하 증가배수/최대가용배수/임계상황판단

* 가용량 경보 시스템 운영 (대쉬보드)

### 효과

* 임계 상황 발생 횟수 대폭 감소

## 대쉬보드 제작

![](https://image.slidesharecdn.com/216sresearchreliabilityengineering-181012022623/95/216search-reliability-engineering-25-638.jpg?cb=1539318282)ㅈ

새로운 지표 개발 -> 관제 범위 확대 -> 시스템 개발 -> 새로운 방법론 개발 

위 사이클 반복함

## 경보피로

그러다 경보가 너무 많이 발생해서 SRE 팀이 엄청난 피로를 겪기 시작함.

필요해서 도입한건데 너무 괴롭힘 -> 경보 피로를 어떻게 줄일까?

### 거짓경보

![](https://image.slidesharecdn.com/216sresearchreliabilityengineering-181012022623/95/216search-reliability-engineering-32-638.jpg?cb=1539318282)

### 자동 경보 분석

* 경험칙, 휴리스틱 : 그래프만 보고 바로 파악 가능하지만 개인차 존재
* 경보 분석 자동화 :  더 이상적인 방법
  * 빠른 대응을 위해 미리 데이터 모아주기
  * 빠른 의사결정을위해 필요한 기본적인 상황 판단만 자동화하기
  * **모든 경우에 대한 대응을 자동화 하는 것이 아니다!!!!!**



## 네이버 SRE의 철학

![](https://image.slidesharecdn.com/216sresearchreliabilityengineering-181012022623/95/216search-reliability-engineering-46-638.jpg?cb=1539318282)

* 문제 분석 관점 : Macro Analysis

  ![](https://image.slidesharecdn.com/216sresearchreliabilityengineering-181012022623/95/216search-reliability-engineering-41-638.jpg?cb=1539318282)

  * 개별 서비스별로 나무를 분석하는 것이 아닌 **전반적인/거시적인 분석**을 한다

* 장애 관제 방식 : Blackbox Monitoring

  ![](https://image.slidesharecdn.com/216sresearchreliabilityengineering-181012022623/95/216search-reliability-engineering-44-638.jpg?cb=1539318282)

## 실제 사례

일상과 밀접한 연관을 가지는 트래픽

![](https://image.slidesharecdn.com/216sresearchreliabilityengineering-181012022623/95/216search-reliability-engineering-48-638.jpg?cb=1539318282)

![](https://image.slidesharecdn.com/216sresearchreliabilityengineering-181012022623/95/216search-reliability-engineering-57-638.jpg?cb=1539318282)

## SRE
시스템이 안정적으로 돌아가게 만들기 위한 모든 활동
* 안정적인 사람이 만들고 운영하는 안정적인 시스템
* 개발자/엔지니어의 심리적, 정신적 안정감도 시스템의 안정도에 큰 영향을 준다

### 문화
* 비난 없는 사후 분석
  * 비난 없는 문화의 부작용 : 문제 제기가 잘 되지 않을 수 있다.
  * 비난이 없는 것보다 사실에 기반해 분석하여 비판하는 것이 더 중요.
* SRE 홍보 활동 : 블로그 글쓰기 / 리포트 발행 / 교육 등 문화 전파



