# Deview 2017 - Day 1
###### * 2017.10.16 - 코엑스 그랜드볼룸*

## Chrominum Binding 기술을 이용하여 Node.js를 Native에 적용해보자
###### 방진호 / 삼성전자 / Web platform
Node.js에서 이미 바인딩을 지원하지만 좋지않다...

#### 왜 네이티브에 적용해야하나? 
* 성능
* Low Level API이용을 위해
* 기존에 잘 만들어진 코드가 Native여서(ex)Open CV)

### 문제점
Argument checking, Type Checking, Type Converting, Memory Management, 가독성 저하 (바인딩 코드가 추가되면서...)
* Boilerplate coe들이 겁나 많아진다.
* 메모리관리 메커니즘이 달라 일일히 체크애줘야한다
* 네이티브 코드 관련 지식이 필요하다 (당연한거 아닌가?)
* 코드 복잡도가 증가한다.

### Chromium을 이용해서 해결하자!
#### V8 Engine과 Blink Engine의 관계
![2017-10-16-11-22-39.jpg](.\images\deview2017_day1\2017-10-16-11-22-39.jpg)

#### V8 Binding
Chromium에서 V8과 Blink를 연결하는 코드이다.
WebIDL에서 자동생성된다. (빌드 파일)
![2017-10-16-11-23-40.jpg](.\images\deview2017_day1\2017-10-16-11-23-40.jpg)

#### WebIDL
V8과 Blink를 연결하는 Later.
Boilerplate code들을 줄여준다

![2017-10-16-11-24-53.jpg](.\images\deview2017_day1\2017-10-16-11-24-53.jpg)

#### Node.js에 AutoBinding을 적용하면
IDL를 제외하고는 추가적인 바인딩 코드를 작성하지 않아도 된다.
바인딩코드와 인터페이스가 명확히 분리된다.
네이티브 관련 지식이 깊게까지는 필요하지 않다.

![2017-10-16-11-27-35.jpg](.\images\deview2017_day1\2017-10-16-11-27-35.jpg)

### Node.js를 위한 AutoBinding 구현하기!
Node.js Auto Binding을 구현하기 위해는 UDE Parser와 Code Generator를 구현하면 된다! ~~참 쉽죠?~~
* Front : IDL Parser를 구현한다. 이미 잘 구현된 WebIDL가 있음.
* Back L Code Generator를 구현한다.Nunjucks Template Engine

#### IDL Parser (Front-end)
* 컴파일러의 프론트엔드역할. Intermediate Representatoon을 생성

#### Code Generator (Back-end)
* 컴파일러의 백엔드의 역할. IR을 Input으로 최종결과물 (바인딩 코드) 생성.
* 코드 생성을 위해 Nunjucks Template Engine을 사용.
* 복잡한 타입매핑/컨버팅은 개발자에게 노출하지 않도록 되어있음.

그런데.. 이걸 언제 다 구현하고 앉아있찌..?
### 관련 오픈소스가 존재한다! (개발진행중)
[bacardi 오픈소스](http://www.github.com/lunchclass/bacardi)
> 모두가 같은 삽질을 할 필요는 없으니까....함께 해요 :-)

라고 한다.

### Binding의 문제점
#### Native가 JS보다 느릴 수 있다.
* C8과 Native Addon을 연결하는 바인딩은 생각보다 오버헤드가 크다.
* 즉, 엄밀히 말하자면 네이티브가 느리다기보다는 네이티브와 연결하는 애가 느린 거. 이건 근데 당연하다. 모든 바인딩이 다 그래....
* 그러므로 최대한 한쪽에서 로직이 진행되게 한 후, 필요할때에만 바인딩 콜을 하도록 하자.

![2017-10-16-11-43-58.jpg](.\images\deview2017_day1\2017-10-16-11-43-58.jpg)

![2017-10-16-11-45-02.jpg](.\images\deview2017_day1\2017-10-16-11-45-02.jpg)

#### Type Checking
* 굳이 매번 타입체킹을 할 필요 없다. 명시적으로 No Type Checking을 하도록 추가하자.

## 그런 Rest API로 괜찮은가
###### 이응준/비바리퍼블리카/Credit silo

[참고자료](http://meetup.toast.com/posts/92)


![2017-10-16-12-26-45.jpg](.\images\deview2017_day1\2017-10-16-12-26-45.jpg)
![2017-10-16-12-30-39.jpg](.\images\deview2017_day1\2017-10-16-12-30-39.jpg)


Rest API는 웹을 독립적으로 성장시키기위해 나옴. 현재 웹은 독립적으로 성장중 => 레스트는 성공했어!
하지만 REST API라고 자부하는 대부분의 프로젝트들이 REST아키텍처를 따르지않고있음..절레절레

![2017-10-16-12-31-48.jpg](.\images\deview2017_day1\2017-10-16-12-31-48.jpg)
왜냐면 사실 REST API는 어려움.

![2017-10-16-12-32-59.jpg](.\images\deview2017_day1\2017-10-16-12-32-59.jpg)

### 꼭 REST API여야 하는가?

![2017-10-16-12-33-23.jpg](.\images\deview2017_day1\2017-10-16-12-33-23.jpg)

![2017-10-16-12-35-31.jpg](.\images\deview2017_day1\2017-10-16-12-35-31.jpg)
ㅋㅋㅋㅋ

### 왜 API는 REST가 잘 안될까?!
HTML은 self-desc가 되지만 json은 그렇지 않음. => 개발자의 Api 명세 작성이 필요함.
Html은 a태그를 이용하여 상태전이가 쉽게 일어남. Json은 없음. => 개발자의 api명세 작성이 필요 (이 필드를 이용해서 상태전이하세요!)
이게 잘 안되는 이유가 되나?......... 기본이 안된건데

Json이 셀프디스크립션이 되지않아 좋은점 : 자유도 상승

Json이 상태전이가 되지않아서 좋은점 : 
![2017-10-16-12-41-51.jpg](.\images\deview2017_day1\2017-10-16-12-41-51.jpg)


셀프디스크립션 처리방법
방법1 : 공식 홈피에 정의
방법2 : 
![2017-10-16-12-44-04.jpg](.\images\deview2017_day1\2017-10-16-12-44-04.jpg)

헤이토스
방법1,2 : data
방법3 : http헤더로

![2017-10-16-12-48-11.jpg](.\images\deview2017_day1\2017-10-16-12-48-11.jpg)

## 웨일 브라우저의 보안이야기
###### 조상현/NAVER/Security
### 싱크데이터

![2017-10-16-14-11-24.jpg](.\images\deview2017_day1\2017-10-16-14-11-24.jpg)

여러 사이트의 계정 정보를 저장하는 서비스를 제공하는 업체가 해킹당함.
=> 그안에 네이버 계정도 있었다. => 네이버가 털린것처럼 보임

### 세이프 브라우징
* Drive-by-download attack
![2017-10-16-14-12-58.jpg](.\images\deview2017_day1\2017-10-16-14-12-58.jpg)

* SPAM Mail 
* CVE (Common Vulnerability Exposures)
* Exploit Kit
* MAAS (Malware As a Service)
* RAAS (Ransomware As a Service)
* Massive SQL Injection
* False Positive 0% : 백프로 악성코드에 감염될만한 사이트만 차단
* AMIGO : 행위 기반 악성코드 탐지
VM을 돌려서 VM상에서 해당 사이트에 방문해보도록 하여 행위 탐지.

#### 세이프 브라우징 - 현실
* 치고 빠지기를 잘하는 공격자 : 순간적으로 악성코드를 빼서 탐지되지 않도록 함
* 공격자들이 자동 분석기가 존재한다는 사실을 알고있음
* DGA(Domain Generation Algorithms) : 도메인을 자동으로 만들어서 여러개의 공격 도메인을 만듬. => 블랙리스트 무력화
* 자동 분석 시스템 우회 : Timeout을 걸어서 공격되도록 함. 마우스나 키보드 액션을 리스닝해서 동작하도록 하기도 함ㅋㅋ

#### 그래서..
신뢰할 수 있는 디비를 최대한 모아보자!!!
* 구글 세이프브라우징 DB (Google SafeBrowsing)
* 네이버 내에 있는 악성 사이트/파일 분석 시스템
* URL 검사 
![2017-10-16-14-27-23.jpg](.\images\deview2017_day1\2017-10-16-14-27-23.jpg)
* 다운르드 파일 검사 : 다운로드 파일의 해시값 검사

### 피싱 탐지 및 대응
주소자체가 다름

네이버 관련 사이트가 아닌데 네이버 로그인 화면의 css를 요청하는 경우에는 차단하도록 함. 자기들 css 올려놓은 서버에서 체크하도록 했음. 그래서 웨일은 차단함. (웨일만 차단한다고 홍보하는데.. 이건 웨일만 차단할 수 있는게 맞지...............;;;)
* Image-based Phishing Detection Framework :

### 파밍 탐지 및 대응
도메인은 동일하지만 페이지가 다른 경우. 공유기를 해킹하여 도메인처리 서버를 변경하면 이렇게 될 수 있지
* Content Injection

Https 면 해결된다. 

#### 그렇다면..
* HTTP Strict Transport Security (HSTS) 를 이용하여 http로 접속해도 자동으로 https로 연결되도록 한다.
* HSTS Preload
* DNS Cypt

### 보안 취약점 분석 및 해결
#### 버그 바운티
네이버도 했었다네? 네이버 웨일이 네이버 제품 중에서 최초로 했다고 함.
근데 포상금이 낮아....;;;;; 흠;
아 상시로 하는게 아니구나?;;; 단기로 1개월만 했다고 한다.

### 익스텐션 보안 검수
크롬은 어떻게 하지?
* AD Injection

어찌됬든 구글거 벤치마킹하면서 발전시키고 있다는 내요이었다.

## 오픈소스를 쓰려는 자, Rebase의 무게를 견뎌라
###### 홍영기/Naver/Whale/UI개발
웨일은 오픈소스인 크로미움 기반의 브라우저임

### 리베이스
새로운 버전에 수정사항을 적용하는 것
git rebase로 되는거 아닌가요? 그렇다면 발표를 안했겠죠

### Chromium을 선택
WebKit 기반의 자체 엔진으로 브라우저 개발을 시작했지만 결국 크로미움으로 결정됨. 왜냐.....?! 5년간의 네이버 웹엔진 개발/삽질기 그리고... 라는 글을 봐주세요.

크로미움은 굉장히 빠르게 업데이트 된다.
웨일이 처음 만들어질때는 52 였으나 금방 58버전이 되었음.
낮은 버전의 엔진을 사용한다는 경고창이 계속적으로 나타나서.. 결국 58로의 이사를 결정
메이저버전이 6번이나 올라갔다보니 수많은 파일 변경이 있었음.
어마어마한 컨플릭 발생!
대대적인 리베이스 작업이 시작됨.

음.. 이거 그냥 컨플릭 헤쳐나가기 같은 거군.....흐음...
다른방으로 갈까

## 자율주행 딥러닝
###### 네이버랩스

사고가 일어나지 않게...

차선 변경을 위한 학습을 해보자! => 사이드 백미러
### 비어있는 공간에 대한 학습
차선 폭이 다른 경우와 자동차가 빠르게 다가오는 경우 문제가 됨

### 자동차에 대한 학습
약하게 감독학습시킴.

사각처리는? 전방백미러는? 흠?

## 오픈소스 데이터베이스, 은행 서비스에 첫 발을 내밀다.
###### 성동찬 / 한국카카오은행 (카뱅) / 인프라 / DBA
**MYSQL** in Banking Service !
금융서비스에 오픈소스 데이터베이스를 쓰다니ㄷㄷ 하지만 매우 잘 쓰고 있음!
쓸 수 있지만 잘 써야 한다! 잘 쓰는 법에 대한 고민을 공유하는 자리임!

### 안정성

Oracle RAC vs My SQL

MySQL은 마스터 슬레이브 구조
![2017-10-16-16-11-11.jpg](.\images\deview2017_day1\2017-10-16-16-11-11.jpg)
MY SQL에서 제공하고 우리가 선택한 Replication은 마스터에서 커밋된 데이터를 비동기적으로 복제한다.
![2017-10-16-16-09-31.jpg](.\images\deview2017_day1\2017-10-16-16-09-31.jpg)

#### 문제점
* 마스터/슬레이브 간 데이터가 일치하지 않을 수 있음. 
* 마스터 장애시 유실이 발생할 수 있다.
* 노드 확장이 쉽지 않다.
* 저장 공간은 유한하다....

#### 어떻게 해결했나
1. 서비스 데이터 일관성 보장은?
 : 서비스는 무조건 마스터 노드에서!
2. 데이터 이중화는?
 : 아 못봤어ㅜㅜ
3. 데이터 유실은?
 : Lossless Replication + MHA

#### Lossless replication
![2017-10-16-16-12-11.jpg](.\images\deview2017_day1\2017-10-16-16-12-11.jpg)
슬레이브 어딘가에 변경 이력이 반드시 남아있다.
Lazy Complete 방식
relay log를 보장
![2017-10-16-16-12-34.jpg](.\images\deview2017_day1\2017-10-16-16-12-34.jpg)

#### MHA (Master High Availabilty)
30초 이내로 데이터 유실없이 복구한다.
마스터만을 주기적으로 헬스 체크하여 슬레이브 등을 이용해 복구
데이터 무손실을 보장

![2017-10-16-16-16-38.jpg](.\images\deview2017_day1\2017-10-16-16-16-38.jpg)

#### 더욱더 견고한 서비스 구성을 위한 고민..
VIP Failover (Virtual IP)... 가 아닌
**Domain Failover** 를 사용하였다.@
주의할 점은.. 
![2017-10-16-16-19-43.jpg](.\images\deview2017_day1\2017-10-16-16-19-43.jpg)

2차 장애도 유연하게 대응

![2017-10-16-16-20-37.jpg](.\images\deview2017_day1\2017-10-16-16-20-37.jpg)

### Scale-Out
![2017-10-16-16-23-04.jpg](.\images\deview2017_day1\2017-10-16-16-23-04.jpg)

![2017-10-16-16-23-58.jpg](.\images\deview2017_day1\2017-10-16-16-23-58.jpg)

![2017-10-16-16-24-51.jpg](.\images\deview2017_day1\2017-10-16-16-24-51.jpg)

* 정적 데이터 : 캐시를 늘렸다.
* 동적/히스토리컬 데이터 : 개인별 저장소(?)로 고민중
* 스토리지 엔진을 혼용하여 서버 분리 : Toku DB
* 확장의 기준은 없다. 데이터 성격을 보고 결정한다!

### As an open source dba (소감? 느낌?)
![2017-10-16-16-34-19.jpg](.\images\deview2017_day1\2017-10-16-16-34-19.jpg)


### 결론
* MySQL은 은행에서 중요한 역할을 담당해요
* 안정적인 데이ㅓ 서비스를 하기 위해 Lossless Replication, MHA, Domain Failover를 잘 조합해서 씁니다. 
* 서비스 무한 확장을 대비해서, 데이터 특성을 보고 샤딩을 구성했어요
* 제한된 인력과 예기치 못한 인재방지를 위해 95% 자동화 구성하고 서비스 튜닝 포인트를 찾고있음
* 그래서 우리의 궁극적인 골은...
![2017-10-16-16-37-30.jpg](.\images\deview2017_day1\2017-10-16-16-37-30.jpg)
