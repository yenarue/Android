# Deview 2017 - Day 2
###### *2017.10.17 - 코엑스 그랜드 볼룸*

## 실시간 조작을 통한 Neural Machine Translation 동작 분석 방법
[발표자료](https://www.slideshare.net/deview/222neural-machine-translation-nmt-80852324)
![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-1-638.jpg)

영어-한국어의 attention이 영어-프랑스어보다 더 복잡하다. => 어순이 다르니까... [#Moses](http://www.statmt.org/moses/?n=FactoredTraining.TrainingParameters)

### # t-SNE
![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-22-638.jpg)

#### 문제점
클러스터링이 된 결과를 보기위해서는 문장이 많이 필요함.
-> 하지만 문장이 많아지면 클러스터도 많아짐
-> 해석이 힘들어짐...
=> 문장 하나에만 집중해서 분석할 방법이 없을까?!

![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-26-638.jpg)

ㄷㄷㄷ원이 그리시던 방식과 비슷하군
![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-27-638.jpg?cb=1508200660)

'베이스'와 '그'가 모두 높은 확률을 갖는 이유는?
=> 문장 하나로는 두개의 단어를 구분짓기 어려운 부분
=> 여러 문장 학습이 필요

### # Interaction 기반 분석
![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-29-638.jpg)

단어별 연관도나 가중치를 직접 변경하여 실시간으로 결과를 확인하도록 분석 UI를 구성하였음.

![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-31-638.jpg)

Attention은 계속해서 보여지면 복잡하므로 노드 클릭시에 나타나도록 했음
![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-36-638.jpg)

Attention 가중치 수정
![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-38-638.jpg)

"he"의 가중치를 중여보았더니 결과가 달라졌다. (당연...)
![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-40-638.jpg)

#### Interaction 기반 분석 도입해보니...
* 이전의 시각화방식은 수동적으로 접근하는 느낌이었는데 능동적으로 직접 NMT의 중간 값들을 조작해가며 결과를 확인해가니 이해에 큰 도움이 되었다.

* NMT는 여러 문장을 동시에 생성하기 때문에, 영어-한국어 처럼 번역 문장 후보가 다양한 경우 ateention을 생성하기 어려움

* 후보 문장중에 하나를 고른다음, 그 문장을 위한 새로운 attention을 만들어주면 (중간값을 조정해서) 더 나은 해석이 된.
> 그 다양한 후보들을 그대로 놔두게되면 점점 결과값이 옅어져 문장이 많아질수록 더욱 모호한 해석이 되기 때문에 다른 후보들을 과감히 버려버리고 하나의 후보만을 선택하여 강화시키는 방법인 것 같다. 발표자가 이걸 설명안하고있음. 뒷자리에서 자꾸 저게뭐냐고 하는데 거슬림

### # 결론
![](https://image.slidesharecdn.com/222neuralmachinetranslationnmt-171016102621/95/222neural-machine-translation-nmt-55-638.jpg)

### # 내 생각
많은 부분에서 공감이 된다. 경험이 적다보니 내가 했던 방법이 정말 최선이었을까 싶었는데 확신을 얻어가는 것 같다. 어순이 다른 언어를 변역하는 경우에는 학습 데이터가 늘어날수록 오히려 더 번역이 모호해지는 경우가 많았다. 이러한 부분은 결국 번역될 수 있는 여러가지 방식(어순)중 하나를 골라서 그 어순에 집중하도록 가중치를 수정하는 방식이 최선인 듯 하다.


## RYE, 샤딩을 지원하는 오픈소스 관계형 DBMS
[발표자료](https://www.slideshare.net/deview/223rye-dbms)

shard 확장시 발생할 수 있는 마이그레이션 문제들을 해결한 방법들 소개(?)

### # SQL Routing
![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-17-638.jpg)

* Sharding Group : 
* Sharding catalog : (GroupId, ShardId) 매핑테이블
* shard node table : DB접속을 위한 정보 (ip, port ...)

#### 성능을 위한 고려사항
##### Connection Poling 
* Shard Connection 사용
* Statement pooling
* JDBC 드라이버 내에 커넥션 유지해놓기

##### sharding catalog
* 샤딩에 대한 정보는 DB에 저장해 놓고있는데 매번 요청하면 성능 저하됨
* JDBC 드라이버에 sharding catalog 캐시를 유지함
* sharding catalog version관리 : 최선 버전 인지는 풀링해야 하는 듯?

### # Shard Extenstion
![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-25-638.jpg)
index scan이 더 용이하다

shard-key컬럼으로 시작하는 인덱스가 필요한데 이거슬 primary key를 활용하면 좋다

migrator processor?

![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-27-638.jpg)
Transaction log는 유저 인터렉션 로그이기때문에 끝이라는 개념이없음. 그래서...
![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-28-638.jpg)

> 그럼 그 사이에 유저인터렉션이 들어오면 어떻게되는거지? 큐에 쌓아놓고 펜딩했다가 넣나?

### # 정합성 관리
![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-32-638.jpg)
shard key가 정합성에서 큰 역할을 함
![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-33-638.jpg)

### # 프로세스 아키텍쳐
![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-34-638.jpg)
shard mgmt server?

### # 샤드 구성
![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-35-638.jpg)

### # Rye Open Source Project
[#Github](https://github.com/naver/rye)
CUBRID 프로젝트에서 포크 되었음
![](https://image.slidesharecdn.com/223ryedbms-171016104435/95/223rye-dbms-39-638.jpg)
* CUBRID 아키텍처와 차이점 : 빨간부분
* 쿼리 부분에서 트리거를 제거했다고 함. => 시간/인력이 부족하기때문에 꼭 필요한 부분부터 채워나가기 위해서...(!?)

## 유연하고 확장가능한 빅데이터 환경 구성
### Onyx
![](https://image.slidesharecdn.com/random-171017044847/95/-10-638.jpg)
... 오닉스 홍보다. 세션3으로 갈아타....기를 시도했으나 너무 늦은 탓에 이도저도 아닌 타임이 되어버렸다ㅠㅠ

## ?까먹음 정리필요

## 인공지능 추천 시스템 AiRS 개발기 : 모델링과 시스템
[발표자료](https://www.slideshare.net/deview/airs-80886207)
### # 추천이란?
특정 시점에 유저가 **좋아할만한** 아이템의 리스트를 찾는 것

### # 좋아할만한 아이템의 정의가 뭐지?
추천 모델마다 정의가 다르다.

#### Statistics-based
좋아할 만한 = **통계적으로 유의미한** 아이템
* Chi-Squared : 예상보다 많이 본 것. 상대적인 변화량에 주목
* Cross-Entropy : Continuous Variable. 분포가 많이 다른 경우.
KL-Divergence?

#### Collaborative Filtering
좋아할 만한 = 나와 **비슷한** 유저가 좋아한 아이템
* Neighborhood models : 유저간의 유사도와 아이템간의 유사도를 구함
* Co-occurrence 동시에 발생하는 이벤트에 주목
![](https://image.slidesharecdn.com/deview2017airsfinal-171017063101/95/airs-14-638.jpg)
* Matrix factorization models

#### Deep Learning
좋아할 만한 = 나의 **컨텍스트 벡터와 가까운** 아이템
* RNN for News Recommendation
* CNN for Deep Topic Tagger : 문서내 단어들의 배열을 보고 주제를 추론
CNN은 보통 이미지 분류/학습에 사용되는데, 문서 주제파악에도 사용할 수 있을 것 같아서 적용해보았음.
* Deep CF models
![](https://image.slidesharecdn.com/deview2017airsfinal-171017063101/95/airs-21-638.jpg)

#### 추천 모델 비교
![](https://image.slidesharecdn.com/deview2017airsfinal-171017063101/95/airs-22-638.jpg)

### # 추천 모델 평가
#### 어떤 기준으로 평가하지?
![](https://image.slidesharecdn.com/deview2017airsfinal-171017063101/95/airs-24-638.jpg)

#### 어떤 방법으로 평가하지?
![](https://image.slidesharecdn.com/deview2017airsfinal-171017063101/95/airs-25-638.jpg)
> 온라인 테스트가 비용이 더 많이 드는 이유는 뭐지?

#### 추천 모델 평가 결과!
평가 지표 : 추천모델 정확도 & 실서비스 만족도
![](https://image.slidesharecdn.com/deview2017airsfinal-171017063101/95/airs-26-638.jpg)

결과적으로 성능은 딥러닝이 더 좋지만 컴퓨팅 시간이 증가함
![](https://image.slidesharecdn.com/deview2017airsfinal-171017063101/95/airs-27-638.jpg)

### # 노하우
* Research + DevOps : 러서치와 데스옵스를 함께하는 팀을 만듬
* 개발언어 + 툴 통합 : 각 오픈소스/플랫폼의 전문가가 한명이상 존재. 언어/툴 모두 맞춰서 하나의 팀처럼.
* Cuve-Hive-DOT (C시리즈는 네이버꺼고.. 일반적으로는 HBase-Hive-Redis)
* Hive (Meta store) 카탈로그 기반 데이터 뷰
* Airflow DAGs 기반 관리? 센서를 활용하면 좋다.
> 에어비앤비에서 만든 서비스라는데 알아보자.
* Batch Job Latency Trade-off
Spark vs Hive : 거의 10배 정도의 시간 차이. 스파크를 이용하자ㅎㅎ